{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mottaquikarim/pycontent/blob/master/.out/topics/eda1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis): Part 1\n",
    "\n",
    "### Import Libraries & Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load the data with `imdbID` as the index and make a copy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_orig = pd.read_csv('https://raw.githubusercontent.com/mottaquikarim/pycontent/master/content/raw_data/omdb4500_clean_simple.csv', index_col='imdbID')\n",
    "movies = omdb_orig.copy()\n",
    "print('data loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**For simplicity's sake**, we edited the Genre, Language, and Country columns such that each movie only has one value for each. **This compromises the statistical integrity, but our analysis is only for learning the code. No one's making investment decisions off this info!**\n",
    "\n",
    "## Summary & Descriptive Statistics\n",
    "\n",
    "We'll start by defining some basic stats terms. When speaking about data, a **population** encompasses the *entire* set of items you're interested in, while a **sample** consists of a subset of those items. This is analagous to the difference between all the movies ever made (population) and the movies in our OMDb dataset (sample). Obtaining data on complete populations usually isn't feasible, so most statistical analyses are based on samples.\n",
    "\n",
    "The heart of every quantitative analysis lies in the data's **descriptive statistics.** Descriptive statistics briefly summarize the data to help understand its makeup and organization.\n",
    "\n",
    "## Describing Data in Pandas\n",
    "\n",
    "In a Pandas dataframe, each row represents an item in your sample space, and each column is a variable representing some numerical or categorical characteristic of the items. Thus, each column will have its own set of descriptive statistics. Below is a quick overview of Pandas Series methods that return basic descriptive statistics for each column, or variable...\n",
    "\n",
    "* **`.describe(include=np.object)`** -- returns count, mean, standard deviation, min, max, & IQR (interquartile range)\n",
    "    * *only includes numerical columns by default*\n",
    "\n",
    "^^ We'll define most of these individually below in the context of some of the OMDb variables!\n",
    "\n",
    "### Averages\n",
    "\n",
    "* **`s.mean()`** -- the simple average; \n",
    "    * *Downside is that it's greatly affected by outliers in the data!*\n",
    "* **`s.median()`** -- in a lineup of ordinal data, the median is the middle number or category\n",
    "* **`s.mode()`** -- the number or category that occurs most often in the dataset\n",
    "    * Notice that even if this only returns one value, it returns a Series object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ratings = movies['imdbRating']\n",
    "\n",
    "mean_imdb = imdb_ratings.mean()\n",
    "median_imdb = imdb_ratings.median()\n",
    "mode_imdb = imdb_ratings.mode()\n",
    "\n",
    "print(f'''\n",
    "MEAN: {mean_imdb}, \n",
    "type = {type(mean_imdb)}\n",
    "\n",
    "MEDIAN: {median_imdb}, \n",
    "type = {type(median_imdb)}''')\n",
    "\n",
    "print(f'''\n",
    "MODE: {mode_imdb}, \n",
    "type = {type(mode_imdb)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ranges\n",
    "\n",
    "* **`s.min()`** -- minimum; smallest value in the variable's data\n",
    "* **`s.max()`** -- maximum; largest value in the variable's data\n",
    "* *range* -- max value minus the min value\n",
    "* **`s.quantile(q=0.5)`** -- return value at the given quantile q, where 0 <= q <= 1\n",
    "\n",
    "Most often, people speak of \"quartiles\" which divide the data into 4 equal parts, each containing 25% of the data. As you can see below, the 2nd quartile is always the median.\n",
    "\n",
    "<img src=\"https://github.com/mottaquikarim/pycontent/blob/master/content/images/quartiles.png?raw=true\" style=\"margin: 0 auto;\"/>\n",
    "\n",
    "People use the **IQR (Interquartile Range)** to describe the middle two quartiles of data. You calculate by taking the difference between the 3rd quartile and the 1st quartile. It's more useful than the regular range *because it excludes outliers*, which can skew your analysis.\n",
    "\n",
    "Examine how quartiles overlap with other key statistical measures within the context of the `imdbRating` variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbRating_quantiles = movies['imdbRating'].quantile(q=[0, 0.25, 0.5, 0.75, 1])\n",
    "imdbRating_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we construct a dataframe to label these values contextually:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_quartiles = pd.DataFrame(index=['Min', '1st Quartile', '2nd Quartile (aka Median)', '3rd Quartile', 'Max'])\n",
    "imdb_quartiles['Quantile'] = imdbRating_quantiles.index.values\n",
    "imdb_quartiles['Value per imdbRating'] = imdbRating_quantiles.values\n",
    "imdb_quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, we calculate the IQR:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_iqr = imdb_ratings.quantile(0.75) - imdb_ratings.quantile(0.25)\n",
    "print(f'imdbRating IQR = {imdb_iqr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Relative Frequency\n",
    "\n",
    "We already know about using `s.value_counts()` to obtain a count of each unique value within a Series object, but did you know that we can also get percentages from it? This method has a parameter called `normalize`, which is set to `False` by default. However, when you set it to `True`...\n",
    "\n",
    "**`s.value_counts(normalize=True)`** -- returns percentages that represent each unique value's relative frequency within the data\n",
    "\n",
    "Take a look at the percentage of movies made by each of the top 10 directors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Director'].value_counts(normalize=True).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üèãÔ∏è‚Äç‚ôÄÔ∏è **EXERCISES** üèãÔ∏è‚Äç‚ôÄÔ∏è \n",
    "\n",
    "Discover other interesting descriptive statistics in the \"Basic Stats\" section in your copy of `eda1_psets.ipynb` in Google Drive.\n",
    "\n",
    "## Grouping Data in Pandas\n",
    "\n",
    "In Pandas, groupby statements are similar to pivot tables in that they allow us to segment our population to a specific subset. For example, if we want to know the average movie length by country of production, a groupby statement would make this task much more straightforward. To understand how a groupby statement works, we'll break it down.\n",
    "\n",
    "### Breaking Down GroupBy Statements\n",
    "\n",
    "**1. Split**:\n",
    "\n",
    "**`df.groupby(by=None, sort=True)`** -- return a **GroupBy** object\n",
    "\n",
    "First, use `.groupby()` to separate our dataframe into groups by a specific attribute. The resultant GroupBy object can be thought of as a **collection of groups.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = movies.groupby('Country')\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Printing out `g` above only shows the user the GroupBy object as an abstraction. To get a little more information, access the GroupBy object's `.groups` attribute. This will show you the name of each group and a corresponding subset of rows (referenced by their index labels) from the original dataframe. In our example, you'll see that each unique `Country` represents a subset of movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice the structure of the dict above. What if you wanted to return the movies in a certain group as their own independent dataframe? You'd access the dict key to obtain the group of index labels. You'd then use this group of index labels to filter out your desired rows from the original dataframe. That's what happens behind the scenes if you use the built-in `GroupBy.get_group()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argentina = gb.get_group('Argentina')\n",
    "argentina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2. Apply**: \n",
    "\n",
    "The reason we broke the dataframe into groups was to apply some function or calculation to each group. In our case, we want to know the average Runtime for the movies in each group.\n",
    "\n",
    "We just saw above how to manually get each group as its own dataframe. If we wanted, we could manually calculate the average Runtime for each Country's movies.\n",
    "\n",
    "Here's the result for Argentina's movies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argentina = argentina['Runtime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And Australia... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "australia = gb.get_group('Australia')['Runtime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3. Combine**: \n",
    "\n",
    "Finally, we would combine those results into a Series summarizing the Average Movie Runtime for each country. You could iterate through the groups like you would any dict to record the results dynamically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, group in movies.groupby('Country'):\n",
    "    x = group['Runtime'].mean()\n",
    "    results.update({name: x})\n",
    "\n",
    "\n",
    "avg_runtime_by_country = pd.Series(data=results, name='Average Movie Runtime')\n",
    "avg_runtime_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GroupBy objects eliminate the need to do this manually. If we put the whole groupby statement together, it will do all of these steps for us at once:\n",
    "\n",
    "*Notice that, by default, the data is sorted on the group names.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.groupby('Country')['Runtime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Two More Groupby Examples\n",
    "\n",
    "* For each year of the 1980s, what was the genre distribution of movies made (in percentages)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies['Year'].between(1980, 1989)].groupby('Year')['Genre'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Within a random sample of 100 movies, how many movies were made in each Country?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample100 = movies.sample(100)\n",
    "\n",
    "sample100.groupby('Country')['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üèãÔ∏è‚Äç‚ôÄÔ∏è **EXERCISES** üèãÔ∏è‚Äç‚ôÄÔ∏è \n",
    "\n",
    "Test your comprehension in the \"GroupBy\" section in your copy of `eda1_psets.ipynb` in Google Drive.\n",
    "\n",
    "## Functions Featured\n",
    "\n",
    "* **`.describe(include=np.object)`** -- returns count, mean, standard deviation, min, max, & IQR (interquartile range)\n",
    "    * *only includes numerical columns by default*\n",
    "* **`s.mean()`** -- the simple average; \n",
    "    * *Downside is that it's greatly affected by outliers in the data!*\n",
    "* **`s.median()`** -- in a lineup of ordinal data, the median is the middle number or category\n",
    "* **`s.mode()`** -- the number or category that occurs most often in the dataset\n",
    "* **`s.min()`** -- minimum; smallest value in the variable's data\n",
    "* **`s.max()`** -- maximum; largest value in the variable's data\n",
    "* *range* -- max value minus the min value\n",
    "* **`s.quantile(q=0.5)`** -- return value at the given quantile q, where 0 <= q <= 1\n",
    "* *IQR (Interquartile Range)* -- (3rd quartile minus 1st quartile)\n",
    "* **`s.value_counts(normalize=False, sort=True, ascending=False, dropna=True)`** -- return a Series containing counts -- or, if normalize=True, relative frequencies -- of unique values\n",
    "* **`df.groupby(by=None, sort=True)`** -- return a `Groupby object`\n",
    "* **`gb.groups`** -- from a GroupBy object, returns the group names and a collection of each group's elements \n",
    "* **`gb.get_group(<group_name>)`** -- returns the elements of a specific group in a GroupBy object as a new dataframe object"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
